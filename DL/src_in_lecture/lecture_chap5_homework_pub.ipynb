{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第5回講義 宿題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題. Theanoを用いて, MNISTを多層パーセプトロン(MLP)で学習せよ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 注意"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- homework関数を完成させて提出してください\n",
    "    - 訓練データはtrain_X, train_y, テストデータはtest_Xで与えられます\n",
    "    - train_Xとtrain_yをtrain_X, train_yとvalid_X, valid_yに分けるなどしてモデルを学習させてください\n",
    "    - test_Xに対して予想ラベルpred_yを作り, homework関数の戻り値としてください\\\n",
    "- pred_yのtest_yに対する精度(F値)で評価します\n",
    "- 全体の実行時間がiLect上で60分を超えないようにしてください\n",
    "- homework関数の外には何も書かないでください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CNNは使わないでください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次のような内容のコードが**事前**に実行されます"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from __future__ import division\n",
    "from collections import OrderedDict\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "mnist_X, mnist_y = shuffle(mnist.data.astype('float32'), mnist.target.astype('int32'))\n",
    "\n",
    "mnist_X = mnist_X / 255.0\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(mnist_X, mnist_y, test_size=0.2, random_state=??) # random_stateはこちらで与えます\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次のセルのhomework関数を完成させて提出してください\n",
    "- パッケージのインポートなど, 必要な物はすべて書いてください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "ilect": {
     "is_homework": true
    }
   },
   "outputs": [],
   "source": [
    "def homework(train_X, test_X, train_y):\n",
    "    np.seterr(divide='ignore', invalid='ignore', over = 'ignore')\n",
    "    layer_num = 2\n",
    "    out_dim = 10\n",
    "    eps = 1.0\n",
    "    dims = [len(train_X[0]),40,out_dim]\n",
    "\n",
    "    wname = \"w\" + str(1)\n",
    "    w = [theano.shared(np.random.uniform(low=-0.08, high=0.08, size=(dims[0], dims[1])).astype(\"float32\"), name=wname)]\n",
    "#     w = [np.random.uniform(low = -0.08, high = 0.08, size = (dims[0],dims[1])).astype(\"float64\")]                                                                                                          \n",
    "    bname = \"b\" + str(1)\n",
    "    b = [theano.shared(np.zeros(dims[1]).astype(\"float32\"), name=bname)]\n",
    "#     b = [np.zeros(dims[1]).astype(\"float64\")]                                                                                                                                                              \n",
    "    uname = \"u\" + str(1)\n",
    "    u = [theano.shared(np.zeros(dims[1]).astype(\"float32\"), name=uname)]\n",
    "#    u = [np.zeros(dims[1]).astype(\"float64\")]                                                                                                                                                               \n",
    "    zname = \"z\" + str(1)\n",
    "    z = [theano.shared(np.zeros(dims[1]).astype(\"float32\"), name=zname)]\n",
    "#    z = [np.zeros(dims[1]).astype(\"float64\")]                                                                                                                                                               \n",
    "    dname = \"delta\" + str(1)\n",
    "    delta = [theano.shared(np.zeros(dims[1]).astype(\"float32\"), name=dname)]\n",
    "#    delta = [np.zeros(dims[1]).astype(\"float64\")]                                                                                                                                                           \n",
    "\n",
    "    for i in range(1, layer_num):\n",
    "        wname = \"w\" + str(i)\n",
    "        w.append(theano.shared(np.random.uniform(low=-0.08, high=0.08, size=(dims[i], dims[i + 1])).astype(\"float32\"), name=wname))\n",
    "        bname = \"b\" + str(i)\n",
    "        b.append(theano.shared(np.zeros(dims[i + 1]).astype(\"float32\"), name=bname))\n",
    "        uname = \"u\" + str(i)\n",
    "        u.append(theano.shared(np.zeros(dims[i + 1]).astype(\"float32\"), name=uname))\n",
    "        zname = \"z\" + str(i)\n",
    "        z.append(theano.shared(np.zeros(dims[i + 1]).astype(\"float32\"), name=zname))\n",
    "        dname = \"delta\" + str(i)\n",
    "        delta.append(theano.shared(np.zeros(dims[i + 1]).astype(\"float32\"), name=dname))\n",
    "    \n",
    "    z = T.fvector(\"z\")\n",
    "    w = T.fmatrix(\"w\")\n",
    "    b = T.fvector(\"b\")\n",
    "    u = T.dot(z, w) + b\n",
    "    u_prop = theano.function(inputs = [z, w, b], outputs = u)\n",
    "    z = T.nnet.sigmoid(u)\n",
    "    z_prop = theano.function(inputs = [u], outputs = z)\n",
    "    for epoch in xrange(1):\n",
    "        for x, y in zip(train_X, train_y):\n",
    "            tmp_z = x[np.newaxis, :]\n",
    "            y2 = np.zeros((1,10))\n",
    "            y2[0,y] = 1\n",
    "            print tmp_z.shape\n",
    "            print w[0].shape\n",
    "            #f_prop                                                                                                                                                                                          \n",
    "            for i in xrange(layer_num - 1):\n",
    "                if i == 0:\n",
    "                    print \"test\"\n",
    "                    u[i] = u_prop(tmp_z, w[i], b[i])\n",
    "                    print \"test 1\"\n",
    "#                u[i] = np.dot(tmp_z, w[i]) + b[i]                                                                                                                                                       \n",
    "                else:\n",
    "                    u[i] = u_prop(z[i - 1], w[i], b[i])\n",
    "                    u[i][np.where(u < -20)] = -20\n",
    "                if i == 0:\n",
    "                    print \"test 2\"\n",
    "                z[i] = z_prop(u[i])\n",
    "#                 z[i] = 1 / (1 + np.exp(-u[i])) #sigmoid                                                                                                                                                    \n",
    "            u[layer_num - 1] = u_prop(z[layer_num - 2], w[layer_num - 1], b[layer_num - 1])\n",
    "#            u[layer_num - 1] = np.dot(z[layer_num - 2], w[layer_num - 1]) + b[layer_num - 1]                                                                                                                \n",
    "            u[layer_num - 1][np.where(u < -20)] = -20\n",
    "#            z[layer_num - 1] = np.exp(u[layer_num -1]) / np.sum(np.exp(u[layer_num - 1]), axis = 1, keepdims = True) #softmax                                                                               \n",
    "            #cost = np.sum(-y2 * np.log(z[layer_num - 1]) - (1 - y2)*np.log(1 - z[layer_num - 1]))                                                                                                           \n",
    "            z[layer_num - 1] = T.nnet.softmax(u[layer_num - 1])\n",
    "            tmp_delta = z[layer_num - 1] - y2\n",
    "\n",
    "            #b_prop                                                                                                                                                                                          \n",
    "            for i in xrange(layer_num):\n",
    "                if i == 0:\n",
    "                    delta[layer_num - 1] = tmp_delta\n",
    "                else:\n",
    "                    delta[layer_num - 1 - i] = np.dot(delta[layer_num - i], w[layer_num - i].T) * (1 / ( 1 + np.exp(u[layer_num - 1 - i]))) * (1 - (1 / ( 1 + np.exp(u[layer_num - 1 - i])))) #deriv_sigmoid\n",
    "            #update parameter                                                                                                                                                                                \n",
    "            for i in xrange(layer_num):\n",
    "                if i == 0:\n",
    "                    dW = np.dot(tmp_z.T, delta[i])\n",
    "                    db = np.dot(np.ones(len(tmp_z)), delta[i])\n",
    "                else:\n",
    "                    dW = np.dot(z[i - 1].T, delta[i])\n",
    "                    db = np.dot(np.ones(len(z[i -1])), delta[i])\n",
    "                w[i] = w[i] - eps * dW\n",
    "                b[i] = b[i] - eps * db\n",
    "    #test                                                                                                                                                                                                    \n",
    "    pred_y = np.zeros(len(test_X)).astype(\"int32\")\n",
    "    for j in xrange(len(test_X)):\n",
    "        tmp_z = test_X[j][np.newaxis, :]\n",
    "        for i in xrange(layer_num):\n",
    "            if i == 0:\n",
    "                u[i] = np.dot(tmp_z, w[i]) + b[i]\n",
    "            else:\n",
    "                u[i] = np.dot(z[i - 1], w[i]) + b[i]\n",
    "            z[i] = 1 / (1 + np.exp(-u[i])) #sigmoid                                                                                                                                                          \n",
    "        u[layer_num - 1] = np.dot(z[layer_num - 2], w[layer_num - 1]) + b[layer_num - 1]\n",
    "        z[layer_num - 1] = np.exp(u[layer_num -1]) / np.sum(np.exp(u[layer_num - 1]), axis = 1, keepdims = True) #softmax                                                                                    \n",
    "        pred_y[j] = np.argmax(z[layer_num - 1])\n",
    "\n",
    "    return pred_y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "ilect": {
     "course_id": 1,
     "course_rank": 5,
     "is_evaluation": true
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from collections import OrderedDict\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "def load_mnist():\n",
    "    mnist = fetch_mldata('MNIST original')\n",
    "    mnist_X, mnist_y = shuffle(mnist.data.astype('float32'), mnist.target.astype('int32'))\n",
    "\n",
    "    mnist_X = mnist_X / 255.0\n",
    "\n",
    "    train_X, test_X, train_y, test_y = train_test_split(mnist_X, mnist_y, test_size=0.2, random_state=42)\n",
    "\n",
    "    return (train_X, test_X, train_y, test_y)\n",
    "\n",
    "def check_homework():\n",
    "    train_X, test_X, train_y, test_y = load_mnist()\n",
    "    pred_y = homework(train_X, test_X, train_y)\n",
    "    return f1_score(test_y, pred_y, average='macro')\n",
    "\n",
    "if 'homework' in globals():\n",
    "    result = check_homework()\n",
    "\n",
    "    print \"No Error Occured!\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
